<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/note/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/note/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/note/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CS,Machine Learning,Matlab," />








  <link rel="shortcut icon" type="image/x-icon" href="/note/favicon.ico?v=5.1.0" />






<meta name="description" content="Logistic is one of the most useful regression algorithm, and in this post, I will talk about the algorithm, its optimization method, its implementation and the comparison between logistic regression a">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic Regression">
<meta property="og:url" content="http://imzhen.com/note/2015/10/10/20151010/index.html">
<meta property="og:site_name" content="Zhen Zhang's Blog">
<meta property="og:description" content="Logistic is one of the most useful regression algorithm, and in this post, I will talk about the algorithm, its optimization method, its implementation and the comparison between logistic regression a">
<meta property="og:updated_time" content="2015-10-16T08:21:24.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Logistic Regression">
<meta name="twitter:description" content="Logistic is one of the most useful regression algorithm, and in this post, I will talk about the algorithm, its optimization method, its implementation and the comparison between logistic regression a">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/note/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://imzhen.com/note/2015/10/10/20151010/"/>





  <title> Logistic Regression | Zhen Zhang's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/note/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Zhen Zhang's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/note/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/note/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/note/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', '4sxUzPGMJ5gc4gm5vQxf','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://imzhen.com/note/note/2015/10/10/20151010/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Zhen Zhang">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/note/note/uploads/avatar.jpeg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Zhen Zhang's Blog">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Zhen Zhang's Blog" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Logistic Regression
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2015-10-10T00:51:20-07:00">
                2015-10-10
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Logistic is one of the most useful regression algorithm, and in this post, I will talk about the algorithm, its optimization method, its implementation and the comparison between logistic regression and PLA (perceptron learning algorithm)</p>
<h1 id="Simple_Linear_Regression">Simple Linear Regression</h1><h2 id="Method">Method</h2><p>First let’s see simple linear regression. The formula is:</p>
<p>$$Y = X * \beta$$</p>
<p>Where $Y$, $X$ are all matrix here. I incorporate the intercept into this formula by adding a $(1, 1, …., 1)^T$ column at the left most part of matrix $X$. So the $X$ here is a augmented matrix, and the column from 2 to the end is the variables it will use.</p>
<p>Of course, we can use as many variables as we want, for instance, we can have interaction terms like $X_1X_2$.</p>
<h2 id="Implementation">Implementation</h2><p>Here is the matlab code that implements this simple algorithm.</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">matrix</span> = <span class="title">dimExpand</span><span class="params">(x,order)</span></span></div><div class="line"><span class="comment">% This is one of the core function in regression. Indeed, what this</span></div><div class="line"><span class="comment">% function does is transform the X (independent value) to the desired</span></div><div class="line"><span class="comment">% matrix we need to do the regression based on the order. For example, with</span></div><div class="line"><span class="comment">% order 0, it will give a vector with ones; with order 1, it will append</span></div><div class="line"><span class="comment">% the X itself append to order 0, and so on so forth for higher orders.</span></div><div class="line"></div><div class="line"><span class="comment">% To note, this function has been optimized for matrix calculation, which</span></div><div class="line"><span class="comment">% means you can give either an array or a matrix as the input of X.</span></div><div class="line"></div><div class="line"><span class="comment">% This functions maintains two pointers: one for the augment power (t1), and</span></div><div class="line"><span class="comment">% the other one for the order we need. By calculating them at an appropriate</span></div><div class="line"><span class="comment">% order, we can give this function the magic of accetping a matrix and give an</span></div><div class="line"><span class="comment">% augmented matrix as the output.</span></div><div class="line">	t1 = <span class="number">0</span>;</div><div class="line">	t2 = order;</div><div class="line">	[r,n] = <span class="built_in">size</span>(x);</div><div class="line">	z = <span class="built_in">ones</span>(r, <span class="number">1</span> + n * order);</div><div class="line">	<span class="keyword">while</span> t2 &gt; <span class="number">0</span>;</div><div class="line">		t1 = t1 + n;</div><div class="line">		z(:,t1-n+<span class="number">2</span>:t1+<span class="number">1</span>) = x.^(t1/n);</div><div class="line">		t2 = t2 - <span class="number">1</span>;</div><div class="line">	<span class="keyword">end</span></div><div class="line">	matrix = z;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">coefficient</span> = <span class="title">singlePolyReg</span><span class="params">(x,y,order)</span></span></div><div class="line"><span class="comment">% This function implements the algorithm for polynomial regression.</span></div><div class="line">	z = dimExpand(x,order);</div><div class="line">	coefficient = (transpose(z) * z) \ (transpose(z) * y);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<h1 id="Logistic_regression">Logistic regression</h1><h2 id="Method-1">Method</h2><p>While simple linear regression can produce the predicted value, sometimes we do not need the actual result. We only need to separate the predicted value into two categories, which is a binary classfication problem.</p>
<p>To achieve, we need a simple transformation, which transforms our value to a new value that falls in [0,1] accurately:</p>
<p>$$y = \frac{1}{1+e^{xw}}$$</p>
<p>This is called the sigmoid function, and it satisfies our requirement. So suppose our new value Y already falls into [0,1], then we need to calculate the required w. But the question is, how to calculate the exact value of w, like what we have done in the previouly method, simple linear regression?</p>
<p>It turns out that it is not that easy to calculate the value of w explicitly. So we need to use the optimization method to approximate it.</p>
<h2 id="Optimization">Optimization</h2><p>There are many optimization method that can be applied to this problem. Here I use one of the most widely used one, gradient descent.</p>
<p>The gradient descent algorithm will converge to the local optimal point from all dimension simultaneously. This is different from the coordinate descent, which converges to the local optimal point one dimension at a time. Regarding this, we also need to provide a learning rate, that can be used to control the speed to the optimal point. It too high, it will jump over the local optimal point, if too small, we need to do so many times of calculation.</p>
<p>The formula for gradient descent is:</p>
<p>$$ \mathbf{w} = \mathbf{w} - \alpha * \frac{\partial RSS}{\partial \mathbf{w}} $$</p>
<p>RSS is defined as:</p>
<p>$$ RSS = \frac{1}{2}(\mathbf{y} - sigmoid(\mathbf{X}))^T(\mathbf{y} - sigmoid(\mathbf{X})) $$</p>
<p>In logistic regression, if we take RSS as a convex function, we can redefine it as:</p>
<p>$$<br>\begin{align}<br>RSS &amp;= A + B \\<br>A &amp;= - \mathbf{y} * log(sigmoid(\mathbf{X}\mathbf{w})) \\<br>B &amp;= - (1 - \mathbf{y}) * log(1 - sigmoid(\mathbf{X}\mathbf{w}))<br>\end{align}<br>$$</p>
<p>The first part is the error for $y$ = 1, while the second part is for $y$ = 0.</p>
<p>By applying conditional likelihood on this formulas (proof omitted here), we have:</p>
<p>$$ \mathbf{w} = \mathbf{w} - \alpha * (\mathbf{y} - sigmoid(\mathbf{X}\mathbf{w}))^T\mathbf{X} $$</p>
<p>Where $\alpha$ is learning rate.</p>
<p>There are two thresholds to stop this optimization. One is, we can define a finite number of times, say 2000 times, then after that the algorithm will stop automatically. Or, we can set the format of RSS or cost function, if the error rate reduced for the cost function is small enough, we will stop either.</p>
<h2 id="Implementation-1">Implementation</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">sigmoid</span><span class="params">(x,w)</span></span></div><div class="line"><span class="comment">% This is the sigmoid function designed for logistic regression.</span></div><div class="line">    result = <span class="number">1</span> ./ (<span class="number">1</span> + <span class="built_in">exp</span>(- x * w));</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">costFun</span><span class="params">(x,y,w)</span></span></div><div class="line"><span class="comment">% This function calculates the cost function related to the logistic</span></div><div class="line"><span class="comment">% regression. The definition of cost function is well known, so I will not</span></div><div class="line"><span class="comment">% explain it here.</span></div><div class="line">    result = <span class="number">0</span>;</div><div class="line">    x = dimExpand(x,<span class="number">1</span>);</div><div class="line">    [n, ~] = <span class="built_in">size</span>(x);</div><div class="line">    <span class="keyword">for</span> k = <span class="number">1</span>:n</div><div class="line">        temp = sigmoid(x,w);</div><div class="line">        <span class="keyword">if</span> y(k) == <span class="number">1</span></div><div class="line">            result = result - <span class="built_in">log</span>(temp);</div><div class="line">        <span class="keyword">else</span></div><div class="line">            result = result - <span class="built_in">log</span>(<span class="number">1</span>-temp);</div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">categorizeY</span><span class="params">(threshold,y)</span></span></div><div class="line"><span class="comment">% This function transforms the Y (dependent value) into two categories</span></div><div class="line"><span class="comment">% based on the threshold value given to the function.</span></div><div class="line"></div><div class="line"><span class="comment">% It creates a new array, and will evaluate the value based</span></div><div class="line"><span class="comment">% on the corresponding Y value.</span></div><div class="line">    <span class="built_in">i</span> = <span class="built_in">length</span>(y);</div><div class="line">    result = <span class="built_in">zeros</span>(<span class="built_in">i</span>,<span class="number">1</span>);</div><div class="line">    <span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">i</span></div><div class="line">        <span class="keyword">if</span> y(n) &gt; threshold</div><div class="line">            result(n) = <span class="number">1</span>;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            result(n) = <span class="number">0</span>;</div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">graDescent</span><span class="params">(x,y,w,learnRate)</span></span></div><div class="line"><span class="comment">% This is the core function for gradient descent and use it to do logistic</span></div><div class="line"><span class="comment">% regression. It main logic is, keep looping, until the error rate is less</span></div><div class="line"><span class="comment">% than 0.0001. While looping, it will update the weight vector in all</span></div><div class="line"><span class="comment">% dimensions simultaneously, based on the gradient descent algorithm. Then</span></div><div class="line"><span class="comment">% at last, return the weight vector.</span></div><div class="line">    [~,r] = <span class="built_in">size</span>(x);</div><div class="line">    z = dimExpand(x,<span class="number">1</span>);</div><div class="line">    keep = true;</div><div class="line">    cost = <span class="number">0</span>;</div><div class="line">    <span class="keyword">while</span> keep</div><div class="line">        temp = <span class="built_in">zeros</span>(r+<span class="number">1</span>,<span class="number">1</span>);</div><div class="line">        temp = temp + z' * (sigmoid(z,w) - y);</div><div class="line">        w = w - learnRate * temp;</div><div class="line">        cost\_new = costFun(x,y,w);</div><div class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(cost\_new - cost) / cost &lt;= <span class="number">0.0001</span></div><div class="line">            keep = false;</div><div class="line">        <span class="keyword">end</span></div><div class="line">        cost = cost\_new;</div><div class="line">    <span class="keyword">end</span></div><div class="line">    result = w;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<h1 id="Comparison_between_logistic_regression_and_PLA">Comparison between logistic regression and PLA</h1><p>When looking at this formula:</p>
<p>$$ \mathbf{w} = \mathbf{w} - \alpha * (\mathbf{y} - sigmoid(\mathbf{X}\mathbf{w}))^T\mathbf{X} $$</p>
<p>It reminds us of the previous PLA algorithm. The difference is, first, the learning rate is 1, and second, there is only $(\mathbf{y} - \mathbf{\hat{y}})^T\mathbf{X}$, instead of $(\mathbf{y} - sigmoid(\mathbf{X}\mathbf{w}))^T\mathbf{X}$, and the only difference is, in PLA, the predicted result is either 0 or 1, but in logistic regression, the result can be any value in [0,1], and we set a threshold to determine which category it belongs to (usually 0.5 as the threshold).</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/note/tags/CS/" rel="tag"># CS</a>
          
            <a href="/note/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/note/tags/Matlab/" rel="tag"># Matlab</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/note/2015/09/28/20150928/" rel="next" title="Some thoughts on PLA algorithm">
                <i class="fa fa-chevron-left"></i> Some thoughts on PLA algorithm
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/note/2015/10/16/20151016/" rel="prev" title="Neural Network Algorithm">
                Neural Network Algorithm <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/note/note/uploads/avatar.jpeg"
               alt="Zhen Zhang" />
          <p class="site-author-name" itemprop="name">Zhen Zhang</p>
          <p class="site-description motion-element" itemprop="description">學須靜也 才須學也</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/note/archives">
              <span class="site-state-item-count">14</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          

          
            <div class="site-state-item site-state-tags">
              <a href="/note/tags">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/imzhen" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/imzhen" target="_blank" title="Linkedin">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Linkedin
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Simple_Linear_Regression"><span class="nav-number">1.</span> <span class="nav-text">Simple Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Method"><span class="nav-number">1.1.</span> <span class="nav-text">Method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation"><span class="nav-number">1.2.</span> <span class="nav-text">Implementation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Logistic_regression"><span class="nav-number">2.</span> <span class="nav-text">Logistic regression</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Method-1"><span class="nav-number">2.1.</span> <span class="nav-text">Method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimization"><span class="nav-number">2.2.</span> <span class="nav-text">Optimization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation-1"><span class="nav-number">2.3.</span> <span class="nav-text">Implementation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Comparison_between_logistic_regression_and_PLA"><span class="nav-number">3.</span> <span class="nav-text">Comparison between logistic regression and PLA</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhen Zhang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/note/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/note/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/note/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/note/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/note/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/note/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/note/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/note/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/note/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/note/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/note/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	




  
  

  

  

  

  


</body>
</html>
